{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Week 8 Report\n",
    "\n",
    "### Key Tasks:\n",
    "\n",
    "Filter Dataset to be only containing straight lines\\\n",
    "Create the sub-dataset\\\n",
    "Start modeling prediction containing geometry information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.4-tf\n",
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import pickle\n",
    "\n",
    "import networkx as nx\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "import itertools\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import backend\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential,model_from_json, load_model\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, Embedding, Dense, TimeDistributed, GRU, LSTM, \\\n",
    "                         Dropout, Bidirectional, Conv1D, BatchNormalization\n",
    "\n",
    "print(tf.keras.__version__)\n",
    "print(tf.__version__)\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "\n",
    "from models.model_gcn import GCN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Filtering\n",
    "\n",
    "The criteria for filtering the data is trivial. We will only preserve the designs that are composed of straight lines, and use those data for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparametr: Predict the next words based on the immediate \n",
    "# last train_length number of words seen\n",
    "\n",
    "class DatasetFilter:\n",
    "    '''Class that filters Fusion 360 Dataset files'''\n",
    "    def __init__(self, fileDir:str):\n",
    "\n",
    "        with open(fileDir) as f:\n",
    "            self.originaldata = json.load(f)\n",
    "            self.entities = self.originaldata['entities']\n",
    "            # Construct Dataframe for Debugging\n",
    "            self.df = pd.DataFrame(data = self.originaldata['sequence']).drop(['smt','step','obj'], axis = 1)\n",
    "            self.df['entities']=self.df['entity'].apply(lambda x: (self.originaldata['entities'])[x])\n",
    "            self.df['curveBoolean'] = self.df.apply(self.curve_boolean, axis = 1)\n",
    "            self.curveBoolean = self.df['curveBoolean'].sum()\n",
    "    \n",
    "    def extract_content(self, row):\n",
    "        if row['type'] == 'Sketch':\n",
    "            return (self.originaldata['entities'][row['entity']])['curves'][row['curve']]['type']\n",
    "        else:\n",
    "            return self.originaldata['entities'][row['entity']]\n",
    "\n",
    "    def curve_boolean(self, row) -> int:\n",
    "        flag = 0\n",
    "        if (self.originaldata['entities'][row['entity']])['type'] == 'Sketch':\n",
    "            curve = (self.originaldata['entities'][row['entity']])['curves'][row['curve']]\n",
    "            sketchtype=curve['type']\n",
    "            if sketchtype !='SketchLine':\n",
    "                flag+=1\n",
    "        return flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sourceDir = \"../../r1.0.0/\"\n",
    "targetDir = \"../../straight/\"\n",
    "\n",
    "dataset_path = sourceDir+\"reconstruction/\"\n",
    "\n",
    "with open(train_test) as f:\n",
    "    train_test_split = json.load(f)\n",
    "\n",
    "train_dir = train_test_split['train']\n",
    "test_dir = train_test_split['test']\n",
    "\n",
    "filtered_train = filtered_test = []\n",
    "\n",
    "def filter_dataset(dataset_dir:str):\n",
    "    filtered_index =[]\n",
    "    for filename in dataset_dir:\n",
    "        filedir = \"reconstruction/\"+filename\n",
    "        example_data = DatasetFilter(sourceDir+filedir+'.json')\n",
    "        if example_data.curveBoolean == 0:\n",
    "            filtered_index.append(filename)\n",
    "            try:\n",
    "                shutil.copy(sourceDir+filedir+'.json', targetDir+filedir+'.json')\n",
    "                shutil.copy(sourceDir+filedir+'.obj', targetDir+filedir+'.obj')\n",
    "                shutil.copy(sourceDir+filedir+'.png', targetDir+filedir+'.png')\n",
    "            except FileNotFoundError:\n",
    "                os.mkdir(targetDir+\"reconstruction/\")\n",
    "\n",
    "    return filtered_index\n",
    "\n",
    "filtered_train = filter_dataset(train_dir)\n",
    "filtered_test = filter_dataset(test_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training Data After Filtering:1298\n",
      "Number of TesT Data After Filtering:317\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of Training Data After Filtering:{len(filtered_train)}')\n",
    "print(f'Number of TesT Data After Filtering:{len(filtered_test)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modify UV-Net for Modeling Command Prediction\n",
    "\n",
    "Originally based on https://github.com/AutodeskAILab/Fusion360GalleryDataset/tree/master/tools/regraphnet\n",
    "\n",
    "Instead of predicting the reconstruction commands of objects, this project propose to perform neural command prediction. The same UV-Net network structure is applied, yet for the reconstruction task, our only input would be the current geometry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NodePointer(nn.Module):\n",
    "    def __init__(self,nfeat,nhid,dropout=0.0,Use_GCN=True):\n",
    "        super(NodePointer,self).__init__()\n",
    "        self.Use_GCN=Use_GCN\n",
    "        self.nhid=nhid\n",
    "        if Use_GCN:\n",
    "            self.fc00=nn.Linear(nfeat,nhid)\n",
    "            self.fc01=nn.Linear(nhid,nhid)\n",
    "            self.fc10=nn.Linear(nfeat,nhid)\n",
    "            self.fc11=nn.Linear(nhid,nhid)\n",
    "            self.fc20=nn.Linear(nfeat*2,nhid)\n",
    "            self.fc21=nn.Linear(nhid,nhid)\n",
    "            self.gcn0=GCN(nfeat=nhid,nhid=nhid,dropout=dropout)\n",
    "            self.gcn1=GCN(nfeat=nhid,nhid=nhid,dropout=dropout)\n",
    "            self.gcn2=GCN(nfeat=nhid,nhid=nhid,dropout=dropout)\n",
    "            self.fc02=nn.Linear(nhid,nhid)\n",
    "            self.fc03=nn.Linear(nhid,nhid)\n",
    "            self.fc12=nn.Linear(nhid,nhid)\n",
    "            self.fc13=nn.Linear(nhid,nhid)\n",
    "            self.fc22=nn.Linear(nhid,nhid)\n",
    "            self.fc23=nn.Linear(nhid,nhid)\n",
    "        else:\n",
    "            self.fc00=nn.Linear(nfeat,nhid)\n",
    "            self.fc01=nn.Linear(nhid,nhid)\n",
    "            self.fc10=nn.Linear(nfeat,nhid)\n",
    "            self.fc11=nn.Linear(nhid,nhid)\n",
    "            self.fc20=nn.Linear(nfeat*2,nhid)\n",
    "            self.fc21=nn.Linear(nhid,nhid)\n",
    "        self.fc_operation=nn.Linear(nhid,5)\n",
    "        self.fc0=nn.Linear(nhid*2,nhid*2)\n",
    "        self.fc1=nn.Linear(nhid*2,nhid*2)\n",
    "        self.fc2=nn.Linear(nhid*2,nhid*2)\n",
    "        self.fc3=nn.Linear(nhid*2,nhid*2)\n",
    "        self.fc_start=nn.Linear(nhid*2,1)\n",
    "        self.fc4=nn.Linear(nhid,nhid)\n",
    "        self.fc5=nn.Linear(nhid,nhid)\n",
    "        self.fc6=nn.Linear(nhid,nhid)\n",
    "        self.fc7=nn.Linear(nhid,nhid)\n",
    "        self.fc_end=nn.Linear(nhid,1)\n",
    "        for m in self.modules():\n",
    "            if isinstance(m,nn.Linear):\n",
    "                torch.nn.init.xavier_uniform_(m.weight)\n",
    "                m.bias.data.fill_(0.00)\n",
    "\n",
    "    def forward(self,gpf,use_gpu=True):\n",
    "        x2=torch.cat((gpf[1],gpf[1][gpf[4],:].repeat(gpf[1].size()[0],1)),dim=1)\n",
    "        if self.Use_GCN:\n",
    "            x0=F.relu(self.fc01(F.relu(self.fc00(gpf[1]))))\n",
    "            x0=self.gcn0(x0,gpf[0])\n",
    "            x0=F.relu(self.fc03(F.relu(self.fc02(x0))))\n",
    "            x2=F.relu(self.fc21(F.relu(self.fc20(x2))))\n",
    "            x2=self.gcn2(x2,gpf[0])\n",
    "            x2=F.relu(self.fc23(F.relu(self.fc22(x2))))\n",
    "            if gpf[2].size()[0]==0:\n",
    "                if use_gpu:\n",
    "                    x1=torch.zeros((1,self.nhid)).cuda()\n",
    "                else:\n",
    "                    x1=torch.zeros((1,self.nhid))\n",
    "            else:\n",
    "                x1=F.relu(self.fc11(F.relu(self.fc10(gpf[3]))))\n",
    "                x1=self.gcn1(x1,gpf[2])\n",
    "                x1=F.relu(self.fc13(F.relu(self.fc12(x1))))\n",
    "        else:\n",
    "            x0=F.relu(self.fc01(F.relu(self.fc00(gpf[1]))))\n",
    "            x2=F.relu(self.fc21(F.relu(self.fc20(x2))))\n",
    "            if gpf[2].size()[0]==0:\n",
    "                if use_gpu:\n",
    "                    x1=torch.zeros((1,self.nhid)).cuda()\n",
    "                else:\n",
    "                    x1=torch.zeros((1,self.nhid))\n",
    "            else:\n",
    "                x1=F.relu(self.fc11(F.relu(self.fc10(gpf[3]))))\n",
    "        x1=torch.sum(x1,dim=0,keepdim=True).repeat(x0.size()[0],1)\n",
    "        op=self.fc_operation(x1[0:1,:])\n",
    "        x=torch.cat((x0,x1),dim=1)\n",
    "        x=F.relu(self.fc0(x))\n",
    "        x=F.relu(self.fc1(x))\n",
    "        x=F.relu(self.fc2(x))\n",
    "        x=F.relu(self.fc3(x))\n",
    "        x_start=self.fc_start(x)\n",
    "        x2=F.relu(self.fc4(x2))\n",
    "        x2=F.relu(self.fc5(x2))\n",
    "        x2=F.relu(self.fc6(x2))\n",
    "        x2=F.relu(self.fc7(x2))\n",
    "        x_end=self.fc_end(x2)\n",
    "        return x_start,x_end,op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
